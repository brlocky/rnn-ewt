{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/learn\\AAPL.csv\n",
      "df_for_training              Open        High         Low       Close   HighLow  CloseOpen  \\\n",
      "0        0.113281    0.113281    0.112723    0.112723  0.000558  -0.000558   \n",
      "1        0.115513    0.116071    0.115513    0.115513  0.000558   0.000000   \n",
      "2        0.118862    0.119420    0.118862    0.118862  0.000558   0.000000   \n",
      "3        0.126116    0.126674    0.126116    0.126116  0.000558   0.000000   \n",
      "4        0.132254    0.132813    0.132254    0.132254  0.000559   0.000000   \n",
      "...           ...         ...         ...         ...       ...        ...   \n",
      "10749  182.130005  183.130005  177.350006  178.850006  5.779999  -3.279999   \n",
      "10750  179.690002  180.270004  177.580002  179.800003  2.690002   0.110001   \n",
      "10751  180.869995  180.929993  177.009995  178.190002  3.919998  -2.679993   \n",
      "10752  179.479996  180.750000  177.600006  177.970001  3.149994  -1.509995   \n",
      "10753  177.320007  178.619995  176.550003  177.789993  2.069992   0.469986   \n",
      "\n",
      "       TrendLabel  \n",
      "0              -1  \n",
      "1               0  \n",
      "2               0  \n",
      "3               0  \n",
      "4               0  \n",
      "...           ...  \n",
      "10749          -1  \n",
      "10750           1  \n",
      "10751          -1  \n",
      "10752          -1  \n",
      "10753           1  \n",
      "\n",
      "[10754 rows x 7 columns]\n",
      "trainY [[[-0.47118835]\n",
      "  [-0.01812559]]\n",
      "\n",
      " [[-0.47137334]\n",
      "  [-0.01896723]]\n",
      "\n",
      " [[-0.47155831]\n",
      "  [-0.01812559]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 4.06911167]\n",
      "  [-4.05954549]]\n",
      "\n",
      " [[ 4.06350183]\n",
      "  [-2.29482524]]\n",
      "\n",
      " [[ 4.05891177]\n",
      "  [ 0.69160086]]]\n",
      "Model loaded successfully.\n",
      "Epoch 1/10\n",
      "966/966 [==============================] - 7s 5ms/step - loss: 0.0364 - val_loss: 6.5839\n",
      "Epoch 2/10\n",
      "966/966 [==============================] - 5s 5ms/step - loss: 0.0361 - val_loss: 5.8412\n",
      "Epoch 3/10\n",
      "966/966 [==============================] - 5s 5ms/step - loss: 0.0358 - val_loss: 6.6737\n",
      "Epoch 4/10\n",
      "966/966 [==============================] - 5s 5ms/step - loss: 0.0357 - val_loss: 6.3667\n",
      "Epoch 5/10\n",
      "966/966 [==============================] - 5s 5ms/step - loss: 0.0357 - val_loss: 6.4444\n",
      "Epoch 6/10\n",
      "966/966 [==============================] - 5s 5ms/step - loss: 0.0353 - val_loss: 5.7280\n",
      "Epoch 7/10\n",
      "966/966 [==============================] - 5s 5ms/step - loss: 0.0350 - val_loss: 7.6270\n",
      "Epoch 8/10\n",
      "966/966 [==============================] - 5s 5ms/step - loss: 0.0350 - val_loss: 11.3129\n",
      "Epoch 9/10\n",
      "966/966 [==============================] - 5s 5ms/step - loss: 0.0344 - val_loss: 7.3077\n",
      "Epoch 10/10\n",
      "966/966 [==============================] - 5s 5ms/step - loss: 0.0342 - val_loss: 6.5045\n",
      "INFO:tensorflow:Assets written to: a_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: a_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/learn\\META.csv\n",
      "df_for_training             Open        High         Low       Close    HighLow  CloseOpen  \\\n",
      "0      32.610001   33.590000   30.940001   31.000000   2.649999  -1.610001   \n",
      "1      31.370001   32.500000   31.360001   32.000000   1.139999   0.629999   \n",
      "2      32.950001   33.209999   31.770000   33.029999   1.439999   0.079998   \n",
      "3      32.900002   32.950001   31.110001   31.910000   1.840000  -0.990002   \n",
      "4      31.480000   31.690001   28.650000   28.840000   3.040001  -2.640000   \n",
      "...          ...         ...         ...         ...        ...        ...   \n",
      "2819  313.230011  317.070007  310.459991  316.559998   6.610016   3.329987   \n",
      "2820  314.399994  317.890015  310.109985  312.640015   7.780030  -1.759979   \n",
      "2821  312.880005  313.630005  302.850006  305.209991  10.779999  -7.670014   \n",
      "2822  307.940002  312.339996  303.869995  305.739990   8.470001  -2.200012   \n",
      "2823  302.570007  304.720001  300.359985  301.640015   4.360016  -0.929992   \n",
      "\n",
      "      TrendLabel  \n",
      "0             -1  \n",
      "1              1  \n",
      "2              1  \n",
      "3             -1  \n",
      "4             -1  \n",
      "...          ...  \n",
      "2819           1  \n",
      "2820          -1  \n",
      "2821          -1  \n",
      "2822          -1  \n",
      "2823          -1  \n",
      "\n",
      "[2824 rows x 7 columns]\n",
      "trainY [[[-1.38256273]\n",
      "  [ 0.02987479]]\n",
      "\n",
      " [[-1.37958895]\n",
      "  [ 0.07727028]]\n",
      "\n",
      " [[-1.37455644]\n",
      "  [ 0.00279199]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 1.74835904]\n",
      "  [-2.61750602]]\n",
      "\n",
      " [[ 1.75442094]\n",
      "  [-0.76569601]]\n",
      "\n",
      " [[ 1.70752717]\n",
      "  [-0.33574448]]]\n",
      "Model loaded successfully.\n",
      "Epoch 1/10\n",
      "252/252 [==============================] - 3s 6ms/step - loss: 0.5104 - val_loss: 0.8337\n",
      "Epoch 2/10\n",
      "252/252 [==============================] - 1s 5ms/step - loss: 0.4931 - val_loss: 0.8225\n",
      "Epoch 3/10\n",
      "252/252 [==============================] - 1s 5ms/step - loss: 0.4826 - val_loss: 0.8164\n",
      "Epoch 4/10\n",
      "252/252 [==============================] - 1s 5ms/step - loss: 0.4781 - val_loss: 0.8163\n",
      "Epoch 5/10\n",
      "252/252 [==============================] - 1s 5ms/step - loss: 0.4709 - val_loss: 0.8216\n",
      "Epoch 6/10\n",
      "252/252 [==============================] - 1s 5ms/step - loss: 0.4642 - val_loss: 0.8092\n",
      "Epoch 7/10\n",
      "252/252 [==============================] - 1s 5ms/step - loss: 0.4549 - val_loss: 0.8094\n",
      "Epoch 8/10\n",
      "252/252 [==============================] - 1s 5ms/step - loss: 0.4394 - val_loss: 0.8182\n",
      "Epoch 9/10\n",
      "252/252 [==============================] - 1s 5ms/step - loss: 0.4382 - val_loss: 0.7967\n",
      "Epoch 10/10\n",
      "252/252 [==============================] - 1s 5ms/step - loss: 0.4179 - val_loss: 0.8257\n",
      "INFO:tensorflow:Assets written to: a_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: a_model\\assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from utils import enrich_data, prepare_training_data\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "import matplotlib.pyplot as plt  # Import the matplotlib.pyplot module\n",
    "import os\n",
    "import pandas as pd\n",
    "import shutil  # Import the shutil module for file operations\n",
    "\n",
    "# Define the path to the data folder\n",
    "data_folder = 'data/learn'\n",
    "output_folder = 'training_plots'  # Specify the output folder\n",
    "\n",
    "# Clean the output folder before each run\n",
    "if os.path.exists(output_folder):\n",
    "    shutil.rmtree(output_folder)  # Remove the folder and its contents\n",
    "\n",
    "# Create the output folder\n",
    "os.makedirs(output_folder)\n",
    "\n",
    "\n",
    "# Get a list of all files in the data folder\n",
    "file_list = [filename for filename in os.listdir(data_folder) if filename.endswith('.csv')]\n",
    "\n",
    "# Loop through each file\n",
    "for filename in file_list:\n",
    "    file_path = os.path.join(data_folder, filename)\n",
    "    print(file_path)\n",
    "\n",
    "    # Prepare Data\n",
    "    df, labeled_data, df_for_training, cols = enrich_data(file_path)\n",
    "    #print(df_for_training)\n",
    "\n",
    "    # LSTM uses sigmoid and tanh that are sensitive to magnitude so values need to be normalized\n",
    "    # normalize the dataset\n",
    "    scaler = StandardScaler()\n",
    "    scaler = scaler.fit(df_for_training)\n",
    "    df_for_training_scaled = scaler.transform(df_for_training)\n",
    "    #print('df_for_training', df_for_training)\n",
    "\n",
    "    ## Prepare training data\n",
    "    trainX, trainY = prepare_training_data(df_for_training_scaled)\n",
    "    #print('trainY', trainY)\n",
    "\n",
    "    # Load model weights if available\n",
    "    try:\n",
    "        model = load_model('a_model')\n",
    "        print(\"Model loaded successfully.\")\n",
    "    except:\n",
    "        print(\"No model found. Training from scratch.\")\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(64, activation='relu', input_shape=(\n",
    "            trainX.shape[1], trainX.shape[2]), return_sequences=True))\n",
    "        model.add(LSTM(32, activation='relu', return_sequences=False))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Dense(trainY.shape[1]))\n",
    "        model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "    #model.summary()\n",
    "\n",
    "    # fit the model\n",
    "    history = model.fit(trainX, trainY, epochs=10, batch_size=10, validation_split=0.1, verbose=1)\n",
    "    plt.plot(history.history['loss'], label='Training loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation loss')\n",
    "    plt.legend()\n",
    "    model.save('a_model')\n",
    "\n",
    "    # Save the plot as an image file in the output folder\n",
    "    output_filename = os.path.join(output_folder, os.path.splitext(filename)[0] + '_plot.png')\n",
    "    plt.savefig(output_filename)\n",
    "\n",
    "    # Clear the current figure\n",
    "    plt.clf()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
