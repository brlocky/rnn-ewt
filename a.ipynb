{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/learn\\AAPL.csv\n",
      "trainx [[[-0.47179813 -0.471659   -0.47178895 ... -0.40347792 -0.01812559\n",
      "   -1.0181967 ]\n",
      "  [-0.47174117 -0.47158861 -0.47171697 ... -0.40347792 -0.01728395\n",
      "    0.01752855]\n",
      "  [-0.4716557  -0.47150412 -0.47163057 ... -0.40347792 -0.01728395\n",
      "    0.01752855]\n",
      "  ...\n",
      "  [-0.47082971 -0.47070164 -0.47080994 ... -0.40347792 -0.01812559\n",
      "   -1.0181967 ]\n",
      "  [-0.47100062 -0.4708706  -0.47098272 ... -0.40347792 -0.01812559\n",
      "   -1.0181967 ]\n",
      "  [-0.47115726 -0.47102546 -0.47114107 ... -0.40347792 -0.01812559\n",
      "   -1.0181967 ]]\n",
      "\n",
      " [[-0.47174117 -0.47158861 -0.47171697 ... -0.40347792 -0.01728395\n",
      "    0.01752855]\n",
      "  [-0.4716557  -0.47150412 -0.47163057 ... -0.40347792 -0.01728395\n",
      "    0.01752855]\n",
      "  [-0.47147058 -0.47132111 -0.47144342 ... -0.40347792 -0.01728395\n",
      "    0.01752855]\n",
      "  ...\n",
      "  [-0.47100062 -0.4708706  -0.47098272 ... -0.40347792 -0.01812559\n",
      "   -1.0181967 ]\n",
      "  [-0.47115726 -0.47102546 -0.47114107 ... -0.40347792 -0.01812559\n",
      "   -1.0181967 ]\n",
      "  [-0.47122846 -0.47109584 -0.47121305 ... -0.40347792 -0.01812559\n",
      "   -1.0181967 ]]\n",
      "\n",
      " [[-0.4716557  -0.47150412 -0.47163057 ... -0.40347792 -0.01728395\n",
      "    0.01752855]\n",
      "  [-0.47147058 -0.47132111 -0.47144342 ... -0.40347792 -0.01728395\n",
      "    0.01752855]\n",
      "  [-0.47131393 -0.47116623 -0.47128506 ... -0.40347693 -0.01728395\n",
      "    0.01752855]\n",
      "  ...\n",
      "  [-0.47115726 -0.47102546 -0.47114107 ... -0.40347792 -0.01812559\n",
      "   -1.0181967 ]\n",
      "  [-0.47122846 -0.47109584 -0.47121305 ... -0.40347792 -0.01812559\n",
      "   -1.0181967 ]\n",
      "  [-0.47105758 -0.47091283 -0.4710259  ... -0.40347792 -0.01728395\n",
      "    0.01752855]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 4.26927397  4.27833294  4.31550443 ...  2.28213736  3.25574829\n",
      "    1.05325379]\n",
      "  [ 4.32133517  4.31642827  4.36529776 ...  1.86734899  1.97369644\n",
      "    1.05325379]\n",
      "  [ 4.35068371  4.32071749  4.39986905 ...  0.71191966  0.75194534\n",
      "    1.05325379]\n",
      "  ...\n",
      "  [ 4.38003186  4.34872109  4.41767081 ...  1.1266784   0.67654792\n",
      "    1.05325379]\n",
      "  [ 4.42265066  4.42793981  4.47391364 ...  2.0747575   3.13510155\n",
      "    1.05325379]\n",
      "  [ 4.45965536  4.42819197  4.48965136 ...  1.48221609  0.55585895\n",
      "    1.05325379]]\n",
      "\n",
      " [[ 4.32133517  4.31642827  4.36529776 ...  1.86734899  1.97369644\n",
      "    1.05325379]\n",
      "  [ 4.35068371  4.32071749  4.39986905 ...  0.71191966  0.75194534\n",
      "    1.05325379]\n",
      "  [ 4.41576047  4.43197614  4.45972381 ...  2.77591776  3.51215654\n",
      "    1.05325379]\n",
      "  ...\n",
      "  [ 4.42265066  4.42793981  4.47391364 ...  2.0747575   3.13510155\n",
      "    1.05325379]\n",
      "  [ 4.45965536  4.42819197  4.48965136 ...  1.48221609  0.55585895\n",
      "    1.05325379]\n",
      "  [ 4.4532753   4.52658406  4.49558516 ...  5.10656222  2.99933701\n",
      "    1.05325379]]\n",
      "\n",
      " [[ 4.35068371  4.32071749  4.39986905 ...  0.71191966  0.75194534\n",
      "    1.05325379]\n",
      "  [ 4.41576047  4.43197614  4.45972381 ...  2.77591776  3.51215654\n",
      "    1.05325379]\n",
      "  [ 4.4706289   4.4168391   4.47262359 ...  1.68960978 -2.00824172\n",
      "   -1.0181967 ]\n",
      "  ...\n",
      "  [ 4.45965536  4.42819197  4.48965136 ...  1.48221609  0.55585895\n",
      "    1.05325379]\n",
      "  [ 4.4532753   4.52658406  4.49558516 ...  5.10656222  2.99933701\n",
      "    1.05325379]\n",
      "  [ 4.50406038  4.48218154  4.49171538 ...  3.51658835 -2.97355892\n",
      "   -1.0181967 ]]]\n",
      "trainY [[[-0.47118835]]\n",
      "\n",
      " [[-0.47137334]]\n",
      "\n",
      " [[-0.47155831]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 4.06911167]]\n",
      "\n",
      " [[ 4.06350183]]\n",
      "\n",
      " [[ 4.05891177]]]\n",
      "Model loaded successfully.\n",
      "Epoch 1/100\n",
      "49/49 [==============================] - 3s 19ms/step - loss: 0.0049 - val_loss: 1.7328\n",
      "Epoch 2/100\n",
      "49/49 [==============================] - 1s 15ms/step - loss: 0.0022 - val_loss: 1.6741\n",
      "Epoch 3/100\n",
      "49/49 [==============================] - 1s 14ms/step - loss: 0.0019 - val_loss: 1.2454\n",
      "Epoch 4/100\n",
      "49/49 [==============================] - 1s 14ms/step - loss: 0.0019 - val_loss: 1.9584\n",
      "Epoch 5/100\n",
      "49/49 [==============================] - 1s 15ms/step - loss: 0.0018 - val_loss: 1.9119\n",
      "Epoch 6/100\n",
      "49/49 [==============================] - 1s 14ms/step - loss: 0.0018 - val_loss: 0.6784\n",
      "Epoch 7/100\n",
      "49/49 [==============================] - 1s 14ms/step - loss: 0.0017 - val_loss: 0.7705\n",
      "Epoch 8/100\n",
      "49/49 [==============================] - 1s 15ms/step - loss: 0.0017 - val_loss: 0.5468\n",
      "Epoch 9/100\n",
      "49/49 [==============================] - 1s 15ms/step - loss: 0.0017 - val_loss: 0.6726\n",
      "Epoch 10/100\n",
      "49/49 [==============================] - 1s 15ms/step - loss: 0.0018 - val_loss: 0.8482\n",
      "Epoch 11/100\n",
      "49/49 [==============================] - 1s 14ms/step - loss: 0.0016 - val_loss: 1.1721\n",
      "Epoch 12/100\n",
      "49/49 [==============================] - 1s 14ms/step - loss: 0.0017 - val_loss: 1.0811\n",
      "Epoch 13/100\n",
      "49/49 [==============================] - 1s 15ms/step - loss: 0.0016 - val_loss: 1.0191\n",
      "Epoch 14/100\n",
      "49/49 [==============================] - 1s 14ms/step - loss: 0.0017 - val_loss: 1.0136\n",
      "Epoch 15/100\n",
      "49/49 [==============================] - 1s 15ms/step - loss: 0.0016 - val_loss: 1.1013\n",
      "Epoch 16/100\n",
      "49/49 [==============================] - 1s 14ms/step - loss: 0.0016 - val_loss: 0.9846\n",
      "Epoch 17/100\n",
      "49/49 [==============================] - 1s 15ms/step - loss: 0.0017 - val_loss: 1.0883\n",
      "Epoch 18/100\n",
      "49/49 [==============================] - 1s 15ms/step - loss: 0.0017 - val_loss: 1.3242\n",
      "Epoch 19/100\n",
      "49/49 [==============================] - 1s 15ms/step - loss: 0.0015 - val_loss: 1.7341\n",
      "Epoch 20/100\n",
      "49/49 [==============================] - 1s 15ms/step - loss: 0.0015 - val_loss: 1.6373\n",
      "Epoch 21/100\n",
      "49/49 [==============================] - 1s 15ms/step - loss: 0.0016 - val_loss: 1.5338\n",
      "Epoch 22/100\n",
      "49/49 [==============================] - 1s 15ms/step - loss: 0.0016 - val_loss: 1.4155\n",
      "Epoch 23/100\n",
      "49/49 [==============================] - 1s 14ms/step - loss: 0.0017 - val_loss: 1.5513\n",
      "Epoch 24/100\n",
      "49/49 [==============================] - 1s 15ms/step - loss: 0.0015 - val_loss: 1.4801\n",
      "Epoch 25/100\n",
      "49/49 [==============================] - 1s 15ms/step - loss: 0.0015 - val_loss: 0.9334\n",
      "Epoch 26/100\n",
      "49/49 [==============================] - 1s 15ms/step - loss: 0.0015 - val_loss: 1.0542\n",
      "Epoch 27/100\n",
      "49/49 [==============================] - 1s 15ms/step - loss: 0.0016 - val_loss: 1.5129\n",
      "Epoch 28/100\n",
      "49/49 [==============================] - 1s 15ms/step - loss: 0.0015 - val_loss: 1.8402\n",
      "Epoch 29/100\n",
      "49/49 [==============================] - 1s 15ms/step - loss: 0.0016 - val_loss: 2.0660\n",
      "Epoch 30/100\n",
      "49/49 [==============================] - 1s 15ms/step - loss: 0.0015 - val_loss: 1.7294\n",
      "Epoch 31/100\n",
      "49/49 [==============================] - 1s 14ms/step - loss: 0.0015 - val_loss: 2.1827\n",
      "Epoch 32/100\n",
      "49/49 [==============================] - 1s 14ms/step - loss: 0.0017 - val_loss: 1.8963\n",
      "Epoch 33/100\n",
      "49/49 [==============================] - 1s 14ms/step - loss: 0.0015 - val_loss: 2.0279\n",
      "Epoch 34/100\n",
      "49/49 [==============================] - 1s 15ms/step - loss: 0.0015 - val_loss: 1.6412\n",
      "Epoch 35/100\n",
      "49/49 [==============================] - 1s 15ms/step - loss: 0.0016 - val_loss: 1.9072\n",
      "Epoch 36/100\n",
      "49/49 [==============================] - 1s 14ms/step - loss: 0.0014 - val_loss: 1.8864\n",
      "Epoch 37/100\n",
      "49/49 [==============================] - 1s 15ms/step - loss: 0.0015 - val_loss: 2.0684\n",
      "Epoch 38/100\n",
      "49/49 [==============================] - 1s 15ms/step - loss: 0.0015 - val_loss: 1.9106\n",
      "Epoch 39/100\n",
      "49/49 [==============================] - 1s 15ms/step - loss: 0.0014 - val_loss: 1.8058\n",
      "Epoch 40/100\n",
      "49/49 [==============================] - 1s 15ms/step - loss: 0.0016 - val_loss: 2.1973\n",
      "Epoch 41/100\n",
      "49/49 [==============================] - 1s 15ms/step - loss: 0.0016 - val_loss: 2.2039\n",
      "Epoch 42/100\n",
      "49/49 [==============================] - 1s 14ms/step - loss: 0.0015 - val_loss: 1.9812\n",
      "Epoch 43/100\n",
      "49/49 [==============================] - 1s 14ms/step - loss: 0.0016 - val_loss: 1.6997\n",
      "Epoch 44/100\n",
      "49/49 [==============================] - 1s 15ms/step - loss: 0.0016 - val_loss: 1.8955\n",
      "Epoch 45/100\n",
      "49/49 [==============================] - 1s 14ms/step - loss: 0.0016 - val_loss: 2.2470\n",
      "Epoch 46/100\n",
      "49/49 [==============================] - 1s 15ms/step - loss: 0.0015 - val_loss: 2.2906\n",
      "Epoch 47/100\n",
      "49/49 [==============================] - 1s 14ms/step - loss: 0.0015 - val_loss: 2.2400\n",
      "Epoch 48/100\n",
      "49/49 [==============================] - 1s 14ms/step - loss: 0.0016 - val_loss: 2.4802\n",
      "Epoch 49/100\n",
      "49/49 [==============================] - 1s 15ms/step - loss: 0.0016 - val_loss: 2.6795\n",
      "Epoch 50/100\n",
      "49/49 [==============================] - 1s 15ms/step - loss: 0.0016 - val_loss: 2.3539\n",
      "Epoch 51/100\n",
      "49/49 [==============================] - 1s 15ms/step - loss: 0.0016 - val_loss: 2.2907\n",
      "Epoch 52/100\n",
      "49/49 [==============================] - 1s 15ms/step - loss: 0.0015 - val_loss: 2.8153\n",
      "Epoch 53/100\n",
      "49/49 [==============================] - 1s 16ms/step - loss: 0.0015 - val_loss: 2.9631\n",
      "Epoch 54/100\n",
      "49/49 [==============================] - 1s 15ms/step - loss: 0.0014 - val_loss: 3.2797\n",
      "Epoch 55/100\n",
      "49/49 [==============================] - 1s 15ms/step - loss: 0.0014 - val_loss: 3.0897\n",
      "Epoch 56/100\n",
      "49/49 [==============================] - 1s 15ms/step - loss: 0.0014 - val_loss: 2.3355\n",
      "Epoch 57/100\n",
      "49/49 [==============================] - 1s 15ms/step - loss: 0.0015 - val_loss: 2.3062\n",
      "Epoch 58/100\n",
      "49/49 [==============================] - 1s 15ms/step - loss: 0.0014 - val_loss: 2.6470\n",
      "Epoch 59/100\n",
      "49/49 [==============================] - 1s 15ms/step - loss: 0.0015 - val_loss: 2.8901\n",
      "Epoch 60/100\n",
      "49/49 [==============================] - 1s 15ms/step - loss: 0.0017 - val_loss: 2.8472\n",
      "Epoch 61/100\n",
      "49/49 [==============================] - 1s 15ms/step - loss: 0.0016 - val_loss: 3.2438\n",
      "Epoch 62/100\n",
      "49/49 [==============================] - 1s 15ms/step - loss: 0.0015 - val_loss: 2.3329\n",
      "Epoch 63/100\n",
      "49/49 [==============================] - 1s 15ms/step - loss: 0.0014 - val_loss: 2.7609\n",
      "Epoch 64/100\n",
      "49/49 [==============================] - 1s 15ms/step - loss: 0.0014 - val_loss: 2.4934\n",
      "Epoch 65/100\n",
      "49/49 [==============================] - 1s 14ms/step - loss: 0.0014 - val_loss: 2.3791\n",
      "Epoch 66/100\n",
      "49/49 [==============================] - 1s 15ms/step - loss: 0.0017 - val_loss: 2.1391\n",
      "Epoch 67/100\n",
      "49/49 [==============================] - 1s 15ms/step - loss: 0.0015 - val_loss: 1.8977\n",
      "Epoch 68/100\n",
      "49/49 [==============================] - 1s 15ms/step - loss: 0.0016 - val_loss: 2.0614\n",
      "Epoch 69/100\n",
      "49/49 [==============================] - 1s 15ms/step - loss: 0.0016 - val_loss: 1.8654\n",
      "Epoch 70/100\n",
      "49/49 [==============================] - 1s 15ms/step - loss: 0.0015 - val_loss: 1.7457\n",
      "Epoch 71/100\n",
      "49/49 [==============================] - 1s 15ms/step - loss: 0.0015 - val_loss: 1.6715\n",
      "Epoch 72/100\n",
      "49/49 [==============================] - 1s 15ms/step - loss: 0.0014 - val_loss: 1.9663\n",
      "Epoch 73/100\n",
      "49/49 [==============================] - 1s 15ms/step - loss: 0.0015 - val_loss: 1.9290\n",
      "Epoch 74/100\n",
      "49/49 [==============================] - 1s 16ms/step - loss: 0.0014 - val_loss: 2.1003\n",
      "Epoch 75/100\n",
      "49/49 [==============================] - 1s 16ms/step - loss: 0.0015 - val_loss: 2.2379\n",
      "Epoch 76/100\n",
      "49/49 [==============================] - 1s 15ms/step - loss: 0.0014 - val_loss: 1.9280\n",
      "Epoch 77/100\n",
      "49/49 [==============================] - 1s 15ms/step - loss: 0.0015 - val_loss: 2.1008\n",
      "Epoch 78/100\n",
      "49/49 [==============================] - 1s 15ms/step - loss: 0.0015 - val_loss: 2.0315\n",
      "Epoch 79/100\n",
      "49/49 [==============================] - 1s 15ms/step - loss: 0.0015 - val_loss: 2.0338\n",
      "Epoch 80/100\n",
      "49/49 [==============================] - 1s 15ms/step - loss: 0.0015 - val_loss: 2.4134\n",
      "Epoch 81/100\n",
      "49/49 [==============================] - 1s 15ms/step - loss: 0.0014 - val_loss: 2.1497\n",
      "Epoch 82/100\n",
      "49/49 [==============================] - 1s 15ms/step - loss: 0.0014 - val_loss: 2.4526\n",
      "Epoch 83/100\n",
      "49/49 [==============================] - 1s 15ms/step - loss: 0.0014 - val_loss: 2.5548\n",
      "Epoch 84/100\n",
      "49/49 [==============================] - 1s 15ms/step - loss: 0.0015 - val_loss: 2.5099\n",
      "Epoch 85/100\n",
      "49/49 [==============================] - 1s 15ms/step - loss: 0.0015 - val_loss: 2.7032\n",
      "Epoch 86/100\n",
      "49/49 [==============================] - 1s 15ms/step - loss: 0.0014 - val_loss: 2.2673\n",
      "Epoch 87/100\n",
      "49/49 [==============================] - 1s 16ms/step - loss: 0.0016 - val_loss: 2.6876\n",
      "Epoch 88/100\n",
      "49/49 [==============================] - 1s 15ms/step - loss: 0.0015 - val_loss: 1.8416\n",
      "Epoch 89/100\n",
      "49/49 [==============================] - 1s 15ms/step - loss: 0.0015 - val_loss: 2.0127\n",
      "Epoch 90/100\n",
      "49/49 [==============================] - 1s 15ms/step - loss: 0.0015 - val_loss: 2.1517\n",
      "Epoch 91/100\n",
      "49/49 [==============================] - 1s 15ms/step - loss: 0.0015 - val_loss: 2.0180\n",
      "Epoch 92/100\n",
      "49/49 [==============================] - 1s 15ms/step - loss: 0.0015 - val_loss: 2.1250\n",
      "Epoch 93/100\n",
      "49/49 [==============================] - 1s 15ms/step - loss: 0.0015 - val_loss: 2.1905\n",
      "Epoch 94/100\n",
      "49/49 [==============================] - 1s 15ms/step - loss: 0.0015 - val_loss: 2.4551\n",
      "Epoch 95/100\n",
      "49/49 [==============================] - 1s 15ms/step - loss: 0.0015 - val_loss: 2.4710\n",
      "Epoch 96/100\n",
      "49/49 [==============================] - 1s 14ms/step - loss: 0.0015 - val_loss: 2.6932\n",
      "Epoch 97/100\n",
      "49/49 [==============================] - 1s 15ms/step - loss: 0.0014 - val_loss: 3.0612\n",
      "Epoch 98/100\n",
      "49/49 [==============================] - 1s 15ms/step - loss: 0.0014 - val_loss: 2.9057\n",
      "Epoch 99/100\n",
      "49/49 [==============================] - 1s 15ms/step - loss: 0.0015 - val_loss: 2.6566\n",
      "Epoch 100/100\n",
      "49/49 [==============================] - 1s 14ms/step - loss: 0.0015 - val_loss: 2.8686\n",
      "INFO:tensorflow:Assets written to: a_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: a_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/learn\\AMD.csv\n",
      "trainx [[[-0.71879923 -0.60948084 -0.60598071 ... -0.59218119  1.86884062\n",
      "    1.00630645]\n",
      "  [-0.71879923 -0.61034789 -0.6064332  ... -0.60106133  1.84758485\n",
      "    1.00630645]\n",
      "  [-0.71879923 -0.61208204 -0.61095832 ... -0.54778217  1.78381757\n",
      "    1.00630645]\n",
      "  ...\n",
      "  [-0.71879923 -0.6289899  -0.62724869 ... -0.57442175  1.52874841\n",
      "    1.00630645]\n",
      "  [-0.71879923 -0.62855635 -0.62860623 ... -0.53890203  1.56417446\n",
      "    1.00630645]\n",
      "  [-0.71879923 -0.6268222  -0.62498616 ... -0.5744209   1.61377146\n",
      "    1.00630645]]\n",
      "\n",
      " [[-0.71879923 -0.61034789 -0.6064332  ... -0.60106133  1.84758485\n",
      "    1.00630645]\n",
      "  [-0.71879923 -0.61208204 -0.61095832 ... -0.54778217  1.78381757\n",
      "    1.00630645]\n",
      "  [-0.71879923 -0.61641736 -0.62272357 ... -0.40570413  1.61377146\n",
      "    1.00630645]\n",
      "  ...\n",
      "  [-0.71879923 -0.62855635 -0.62860623 ... -0.53890203  1.56417446\n",
      "    1.00630645]\n",
      "  [-0.71879923 -0.6268222  -0.62498616 ... -0.5744209   1.61377146\n",
      "    1.00630645]\n",
      "  [-0.71879923 -0.62378748 -0.62181857 ... -0.57442175  1.66336779\n",
      "    1.00630645]]\n",
      "\n",
      " [[-0.71879923 -0.61208204 -0.61095832 ... -0.54778217  1.78381757\n",
      "    1.00630645]\n",
      "  [-0.71879923 -0.61641736 -0.62272357 ... -0.40570413  1.61377146\n",
      "    1.00630645]\n",
      "  [-0.71879923 -0.62335393 -0.62634369 ... -0.47674272  1.57125994\n",
      "    1.00630645]\n",
      "  ...\n",
      "  [-0.71879923 -0.6268222  -0.62498616 ... -0.5744209   1.61377146\n",
      "    1.00630645]\n",
      "  [-0.71879923 -0.62378748 -0.62181857 ... -0.57442175  1.66336779\n",
      "    1.00630645]\n",
      "  [-0.71879923 -0.62248688 -0.62272357 ... -0.53002274  1.5925157\n",
      "    1.00630645]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 3.85647291  3.8806903   3.91445463 ...  2.67063379  1.03788109\n",
      "    1.00630645]\n",
      "  [ 3.84130203  3.91440188  3.93834697 ...  2.89227766  1.13310691\n",
      "    1.00630645]\n",
      "  [ 4.00396718  3.95518895  4.03435156 ...  1.84374717 -0.76460828\n",
      "   -1.05355796]\n",
      "  ...\n",
      "  [ 4.17674609  4.34474594  4.26936759 ...  5.2109876  -0.35649355\n",
      "   -1.05355796]\n",
      "  [ 4.16747498  4.20823424  4.15989638 ...  4.56310448  1.41198524\n",
      "    1.00630645]\n",
      "  [ 4.23490119  4.19117048  4.26676122 ...  2.11652966  0.05841418\n",
      "    1.00630645]]\n",
      "\n",
      " [[ 3.84130203  3.91440188  3.93834697 ...  2.89227766  1.13310691\n",
      "    1.00630645]\n",
      "  [ 4.00396718  3.95518895  4.03435156 ...  1.84374717 -0.76460828\n",
      "   -1.05355796]\n",
      "  [ 4.04442271  4.03551426  4.1459953  ...  1.29816174  0.39851182\n",
      "    1.00630645]\n",
      "  ...\n",
      "  [ 4.16747498  4.20823424  4.15989638 ...  4.56310448  1.41198524\n",
      "    1.00630645]\n",
      "  [ 4.23490119  4.19117048  4.26676122 ...  2.11652966  0.05841418\n",
      "    1.00630645]\n",
      "  [ 4.39293076  4.32601704  4.28240002 ...  4.57163085 -3.51255399\n",
      "   -1.05355796]]\n",
      "\n",
      " [[ 4.00396718  3.95518895  4.03435156 ...  1.84374717 -0.76460828\n",
      "   -1.05355796]\n",
      "  [ 4.04442271  4.03551426  4.1459953  ...  1.29816174  0.39851182\n",
      "    1.00630645]\n",
      "  [ 4.13418371  4.12041774  4.23722133 ...  1.24701631  0.24886513\n",
      "    1.00630645]\n",
      "  ...\n",
      "  [ 4.23490119  4.19117048  4.26676122 ...  2.11652966  0.05841418\n",
      "    1.00630645]\n",
      "  [ 4.39293076  4.32601704  4.28240002 ...  4.57163085 -3.51255399\n",
      "   -1.05355796]\n",
      "  [ 4.12575526  4.05049726  4.00828704 ...  4.30737473 -3.40372176\n",
      "   -1.05355796]]]\n",
      "trainY [[[-0.63292735]]\n",
      "\n",
      " [[-0.63248464]]\n",
      "\n",
      " [[-0.62672953]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 3.95747864]]\n",
      "\n",
      " [[ 3.94727892]]\n",
      "\n",
      " [[ 3.83423101]]]\n",
      "Model loaded successfully.\n",
      "Epoch 1/100\n",
      "50/50 [==============================] - 3s 18ms/step - loss: 0.0076 - val_loss: 2.8521\n",
      "Epoch 2/100\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0054 - val_loss: 3.0031\n",
      "Epoch 3/100\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0047 - val_loss: 3.4890\n",
      "Epoch 4/100\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0042 - val_loss: 3.1255\n",
      "Epoch 5/100\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0039 - val_loss: 3.2857\n",
      "Epoch 6/100\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0038 - val_loss: 3.3047\n",
      "Epoch 7/100\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0035 - val_loss: 3.6792\n",
      "Epoch 8/100\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0035 - val_loss: 3.7682\n",
      "Epoch 9/100\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0034 - val_loss: 3.4989\n",
      "Epoch 10/100\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0032 - val_loss: 3.6762\n",
      "Epoch 11/100\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0032 - val_loss: 3.8516\n",
      "Epoch 12/100\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0031 - val_loss: 3.0781\n",
      "Epoch 13/100\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0029 - val_loss: 3.3644\n",
      "Epoch 14/100\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0030 - val_loss: 3.2571\n",
      "Epoch 15/100\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0030 - val_loss: 3.7871\n",
      "Epoch 16/100\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0028 - val_loss: 3.2212\n",
      "Epoch 17/100\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0029 - val_loss: 3.7676\n",
      "Epoch 18/100\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0028 - val_loss: 3.4209\n",
      "Epoch 19/100\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0028 - val_loss: 3.4692\n",
      "Epoch 20/100\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0028 - val_loss: 3.5939\n",
      "Epoch 21/100\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0027 - val_loss: 3.4545\n",
      "Epoch 22/100\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0027 - val_loss: 3.3985\n",
      "Epoch 23/100\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0027 - val_loss: 3.3212\n",
      "Epoch 24/100\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0026 - val_loss: 3.7265\n",
      "Epoch 25/100\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0027 - val_loss: 3.2089\n",
      "Epoch 26/100\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0027 - val_loss: 3.3004\n",
      "Epoch 27/100\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0026 - val_loss: 3.6576\n",
      "Epoch 28/100\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0027 - val_loss: 3.4747\n",
      "Epoch 29/100\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0027 - val_loss: 3.3988\n",
      "Epoch 30/100\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0026 - val_loss: 3.2621\n",
      "Epoch 31/100\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0025 - val_loss: 3.2912\n",
      "Epoch 32/100\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0025 - val_loss: 3.3445\n",
      "Epoch 33/100\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0025 - val_loss: 3.3286\n",
      "Epoch 34/100\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0025 - val_loss: 3.4127\n",
      "Epoch 35/100\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0027 - val_loss: 3.3693\n",
      "Epoch 36/100\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0026 - val_loss: 3.4810\n",
      "Epoch 37/100\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0026 - val_loss: 3.1502\n",
      "Epoch 38/100\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0025 - val_loss: 3.3995\n",
      "Epoch 39/100\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0025 - val_loss: 3.1476\n",
      "Epoch 40/100\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0026 - val_loss: 3.4423\n",
      "Epoch 41/100\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0026 - val_loss: 3.6446\n",
      "Epoch 42/100\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0025 - val_loss: 3.2743\n",
      "Epoch 43/100\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0025 - val_loss: 3.7390\n",
      "Epoch 44/100\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0025 - val_loss: 3.3538\n",
      "Epoch 45/100\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0024 - val_loss: 3.1162\n",
      "Epoch 46/100\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0025 - val_loss: 3.3865\n",
      "Epoch 47/100\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0024 - val_loss: 3.4111\n",
      "Epoch 48/100\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0024 - val_loss: 3.3101\n",
      "Epoch 49/100\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0024 - val_loss: 3.3110\n",
      "Epoch 50/100\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0023 - val_loss: 3.5162\n",
      "Epoch 51/100\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0024 - val_loss: 3.5579\n",
      "Epoch 52/100\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0025 - val_loss: 3.7922\n",
      "Epoch 53/100\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0023 - val_loss: 3.6298\n",
      "Epoch 54/100\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0024 - val_loss: 4.0455\n",
      "Epoch 55/100\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0024 - val_loss: 3.4503\n",
      "Epoch 56/100\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0024 - val_loss: 3.3800\n",
      "Epoch 57/100\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0024 - val_loss: 3.4674\n",
      "Epoch 58/100\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0024 - val_loss: 3.6602\n",
      "Epoch 59/100\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0022 - val_loss: 3.6231\n",
      "Epoch 60/100\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0025 - val_loss: 3.6144\n",
      "Epoch 61/100\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0024 - val_loss: 3.3658\n",
      "Epoch 62/100\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0023 - val_loss: 3.5604\n",
      "Epoch 63/100\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0024 - val_loss: 3.5532\n",
      "Epoch 64/100\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0024 - val_loss: 3.2819\n",
      "Epoch 65/100\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0024 - val_loss: 3.3501\n",
      "Epoch 66/100\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0023 - val_loss: 3.4495\n",
      "Epoch 67/100\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0023 - val_loss: 3.5930\n",
      "Epoch 68/100\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0024 - val_loss: 3.7262\n",
      "Epoch 69/100\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0023 - val_loss: 3.7215\n",
      "Epoch 70/100\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0023 - val_loss: 3.5269\n",
      "Epoch 71/100\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0023 - val_loss: 4.0695\n",
      "Epoch 72/100\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0023 - val_loss: 3.9728\n",
      "Epoch 73/100\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0023 - val_loss: 3.8945\n",
      "Epoch 74/100\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0023 - val_loss: 3.9711\n",
      "Epoch 75/100\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0022 - val_loss: 4.0382\n",
      "Epoch 76/100\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0023 - val_loss: 4.1229\n",
      "Epoch 77/100\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0023 - val_loss: 3.6170\n",
      "Epoch 78/100\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0022 - val_loss: 4.2528\n",
      "Epoch 79/100\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0022 - val_loss: 3.8393\n",
      "Epoch 80/100\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0023 - val_loss: 4.0604\n",
      "Epoch 81/100\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0022 - val_loss: 4.0570\n",
      "Epoch 82/100\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0023 - val_loss: 3.7907\n",
      "Epoch 83/100\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0023 - val_loss: 4.0009\n",
      "Epoch 84/100\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0023 - val_loss: 4.2246\n",
      "Epoch 85/100\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0023 - val_loss: 4.1750\n",
      "Epoch 86/100\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0022 - val_loss: 4.2099\n",
      "Epoch 87/100\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0023 - val_loss: 3.9681\n",
      "Epoch 88/100\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0023 - val_loss: 3.7145\n",
      "Epoch 89/100\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0022 - val_loss: 3.7483\n",
      "Epoch 90/100\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0023 - val_loss: 3.7567\n",
      "Epoch 91/100\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0022 - val_loss: 3.4832\n",
      "Epoch 92/100\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0023 - val_loss: 3.9534\n",
      "Epoch 93/100\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0024 - val_loss: 3.4227\n",
      "Epoch 94/100\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0022 - val_loss: 3.7151\n",
      "Epoch 95/100\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0023 - val_loss: 3.6031\n",
      "Epoch 96/100\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0023 - val_loss: 3.7029\n",
      "Epoch 97/100\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0023 - val_loss: 4.0654\n",
      "Epoch 98/100\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0021 - val_loss: 3.8217\n",
      "Epoch 99/100\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0023 - val_loss: 4.0071\n",
      "Epoch 100/100\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0021 - val_loss: 3.8174\n",
      "INFO:tensorflow:Assets written to: a_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: a_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/learn\\META.csv\n",
      "trainx [[[-1.36931814 -1.36327046 -1.38342064 ... -0.39069171 -0.56595417\n",
      "   -1.02328922]\n",
      "  [-1.38350592 -1.3755847  -1.37855544 ... -0.86514285  0.1923736\n",
      "    0.97932254]\n",
      "  [-1.36542794 -1.36756351 -1.37380609 ... -0.77088104  0.00617671\n",
      "    0.97932254]\n",
      "  ...\n",
      "  [-1.43865521 -1.4291347  -1.43554781 ... -0.80858576  0.16529114\n",
      "    0.97932254]\n",
      "  [-1.4314469  -1.42563248 -1.4309143  ... -0.83686399 -0.07845741\n",
      "   -1.02328922]\n",
      "  [-1.42801437 -1.42902173 -1.42952425 ... -0.96883022 -0.04798888\n",
      "   -1.02328922]]\n",
      "\n",
      " [[-1.38350592 -1.3755847  -1.37855544 ... -0.86514285  0.1923736\n",
      "    0.97932254]\n",
      "  [-1.36542794 -1.36756351 -1.37380609 ... -0.77088104  0.00617671\n",
      "    0.97932254]\n",
      "  [-1.36600002 -1.37050083 -1.38145139 ... -0.6451983  -0.35606022\n",
      "   -1.02328922]\n",
      "  ...\n",
      "  [-1.4314469  -1.42563248 -1.4309143  ... -0.83686399 -0.07845741\n",
      "   -1.02328922]\n",
      "  [-1.42801437 -1.42902173 -1.42952425 ... -0.96883022 -0.04798888\n",
      "   -1.02328922]\n",
      "  [-1.42595485 -1.42529356 -1.42790251 ... -0.90913139 -0.15293603\n",
      "   -1.02328922]]\n",
      "\n",
      " [[-1.36542794 -1.36756351 -1.37380609 ... -0.77088104  0.00617671\n",
      "    0.97932254]\n",
      "  [-1.36600002 -1.37050083 -1.38145139 ... -0.6451983  -0.35606022\n",
      "   -1.02328922]\n",
      "  [-1.38224734 -1.38473564 -1.40994759 ... -0.26815072 -0.91464919\n",
      "   -1.02328922]\n",
      "  ...\n",
      "  [-1.42801437 -1.42902173 -1.42952425 ... -0.96883022 -0.04798888\n",
      "   -1.02328922]\n",
      "  [-1.42595485 -1.42529356 -1.42790251 ... -0.90913139 -0.15293603\n",
      "   -1.02328922]\n",
      "  [-1.42606927 -1.42280812 -1.42465905 ... -0.92798343  0.19575967\n",
      "    0.97932254]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 1.48425639  1.52616993  1.50917398 ...  1.510259    1.68532429\n",
      "    0.97932254]\n",
      "  [ 1.5164077   1.52842922  1.54867484 ...  0.50165066  0.13820834\n",
      "    0.97932254]\n",
      "  [ 1.51274626  1.49476298  1.50963743 ...  0.62419573 -1.02636746\n",
      "   -1.02328922]\n",
      "  ...\n",
      "  [ 1.82499193  1.81459427  1.8185776  ...  1.13949837 -1.0094449\n",
      "   -1.02328922]\n",
      "  [ 1.77636446  1.77878114  1.78788056 ...  0.97610494  1.0217902\n",
      "    0.97932254]\n",
      "  [ 1.81457989  1.80691207  1.82158951 ...  0.84414374  0.37517934\n",
      "    0.97932254]]\n",
      "\n",
      " [[ 1.5164077   1.52842922  1.54867484 ...  0.50165066  0.13820834\n",
      "    0.97932254]\n",
      "  [ 1.51274626  1.49476298  1.50963743 ...  0.62419573 -1.02636746\n",
      "   -1.02328922]\n",
      "  [ 1.51572123  1.52278049  1.55284519 ...  0.23142874  0.73065158\n",
      "    0.97932254]\n",
      "  ...\n",
      "  [ 1.77636446  1.77878114  1.78788056 ...  0.97610494  1.0217902\n",
      "    0.97932254]\n",
      "  [ 1.81457989  1.80691207  1.82158951 ...  0.84414374  0.37517934\n",
      "    0.97932254]\n",
      "  [ 1.8391796   1.85752451  1.85518251 ...  1.34058522  0.98794474\n",
      "    0.97932254]]\n",
      "\n",
      " [[ 1.51274626  1.49476298  1.50963743 ...  0.62419573 -1.02636746\n",
      "   -1.02328922]\n",
      "  [ 1.51572123  1.52278049  1.55284519 ...  0.23142874  0.73065158\n",
      "    0.97932254]\n",
      "  [ 1.53791826  1.52673467  1.55782615 ...  0.20629634 -0.25112018\n",
      "   -1.02328922]\n",
      "  ...\n",
      "  [ 1.81457989  1.80691207  1.82158951 ...  0.84414374  0.37517934\n",
      "    0.97932254]\n",
      "  [ 1.8391796   1.85752451  1.85518251 ...  1.34058522  0.98794474\n",
      "    0.97932254]\n",
      "  [ 1.84455724  1.82205065  1.75903697 ...  2.96188972 -3.7380697\n",
      "   -1.02328922]]]\n",
      "trainY [[[-1.38256273]]\n",
      "\n",
      " [[-1.37958895]]\n",
      "\n",
      " [[-1.37455644]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 1.74835904]]\n",
      "\n",
      " [[ 1.75442094]]\n",
      "\n",
      " [[ 1.70752717]]]\n",
      "Model loaded successfully.\n",
      "Epoch 1/100\n",
      "13/13 [==============================] - 2s 35ms/step - loss: 0.1058 - val_loss: 0.0929\n",
      "Epoch 2/100\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.0551 - val_loss: 0.1111\n",
      "Epoch 3/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0447 - val_loss: 0.1034\n",
      "Epoch 4/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0400 - val_loss: 0.0970\n",
      "Epoch 5/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0333 - val_loss: 0.0915\n",
      "Epoch 6/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0311 - val_loss: 0.0876\n",
      "Epoch 7/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0262 - val_loss: 0.0894\n",
      "Epoch 8/100\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.0248 - val_loss: 0.0873\n",
      "Epoch 9/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0263 - val_loss: 0.0876\n",
      "Epoch 10/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0228 - val_loss: 0.0813\n",
      "Epoch 11/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0247 - val_loss: 0.0868\n",
      "Epoch 12/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0245 - val_loss: 0.0810\n",
      "Epoch 13/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0237 - val_loss: 0.0878\n",
      "Epoch 14/100\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.0260 - val_loss: 0.0851\n",
      "Epoch 15/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0231 - val_loss: 0.0831\n",
      "Epoch 16/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0225 - val_loss: 0.0891\n",
      "Epoch 17/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0214 - val_loss: 0.0864\n",
      "Epoch 18/100\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.0223 - val_loss: 0.0839\n",
      "Epoch 19/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0212 - val_loss: 0.0825\n",
      "Epoch 20/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0226 - val_loss: 0.0891\n",
      "Epoch 21/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0204 - val_loss: 0.0853\n",
      "Epoch 22/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0215 - val_loss: 0.0876\n",
      "Epoch 23/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0205 - val_loss: 0.0842\n",
      "Epoch 24/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0194 - val_loss: 0.0851\n",
      "Epoch 25/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0215 - val_loss: 0.0894\n",
      "Epoch 26/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0212 - val_loss: 0.0848\n",
      "Epoch 27/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0205 - val_loss: 0.0845\n",
      "Epoch 28/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0200 - val_loss: 0.0835\n",
      "Epoch 29/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0213 - val_loss: 0.0874\n",
      "Epoch 30/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0198 - val_loss: 0.0801\n",
      "Epoch 31/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0207 - val_loss: 0.0841\n",
      "Epoch 32/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0198 - val_loss: 0.0804\n",
      "Epoch 33/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0187 - val_loss: 0.0901\n",
      "Epoch 34/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0197 - val_loss: 0.0899\n",
      "Epoch 35/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0189 - val_loss: 0.0840\n",
      "Epoch 36/100\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.0195 - val_loss: 0.0870\n",
      "Epoch 37/100\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.0222 - val_loss: 0.0846\n",
      "Epoch 38/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0198 - val_loss: 0.0893\n",
      "Epoch 39/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0176 - val_loss: 0.0874\n",
      "Epoch 40/100\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.0194 - val_loss: 0.0798\n",
      "Epoch 41/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0194 - val_loss: 0.0908\n",
      "Epoch 42/100\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.0203 - val_loss: 0.0795\n",
      "Epoch 43/100\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.0206 - val_loss: 0.0869\n",
      "Epoch 44/100\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.0211 - val_loss: 0.0886\n",
      "Epoch 45/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0193 - val_loss: 0.0869\n",
      "Epoch 46/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0189 - val_loss: 0.0833\n",
      "Epoch 47/100\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.0194 - val_loss: 0.0883\n",
      "Epoch 48/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0179 - val_loss: 0.0913\n",
      "Epoch 49/100\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.0195 - val_loss: 0.0885\n",
      "Epoch 50/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0185 - val_loss: 0.0868\n",
      "Epoch 51/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0186 - val_loss: 0.0872\n",
      "Epoch 52/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0190 - val_loss: 0.0904\n",
      "Epoch 53/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0185 - val_loss: 0.0887\n",
      "Epoch 54/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0180 - val_loss: 0.0855\n",
      "Epoch 55/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0183 - val_loss: 0.0869\n",
      "Epoch 56/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0175 - val_loss: 0.0846\n",
      "Epoch 57/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0186 - val_loss: 0.0915\n",
      "Epoch 58/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0185 - val_loss: 0.0884\n",
      "Epoch 59/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0197 - val_loss: 0.0885\n",
      "Epoch 60/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0184 - val_loss: 0.0852\n",
      "Epoch 61/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0189 - val_loss: 0.0827\n",
      "Epoch 62/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0181 - val_loss: 0.0807\n",
      "Epoch 63/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0184 - val_loss: 0.0865\n",
      "Epoch 64/100\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.0194 - val_loss: 0.0843\n",
      "Epoch 65/100\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.0181 - val_loss: 0.0870\n",
      "Epoch 66/100\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.0189 - val_loss: 0.0851\n",
      "Epoch 67/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0185 - val_loss: 0.0904\n",
      "Epoch 68/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0190 - val_loss: 0.0846\n",
      "Epoch 69/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0184 - val_loss: 0.0852\n",
      "Epoch 70/100\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.0183 - val_loss: 0.0927\n",
      "Epoch 71/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0172 - val_loss: 0.0904\n",
      "Epoch 72/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0181 - val_loss: 0.0847\n",
      "Epoch 73/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0192 - val_loss: 0.0843\n",
      "Epoch 74/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0164 - val_loss: 0.0848\n",
      "Epoch 75/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0187 - val_loss: 0.0876\n",
      "Epoch 76/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0184 - val_loss: 0.0929\n",
      "Epoch 77/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0197 - val_loss: 0.0909\n",
      "Epoch 78/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0182 - val_loss: 0.0835\n",
      "Epoch 79/100\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.0186 - val_loss: 0.0866\n",
      "Epoch 80/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0191 - val_loss: 0.0961\n",
      "Epoch 81/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0179 - val_loss: 0.0838\n",
      "Epoch 82/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0174 - val_loss: 0.0793\n",
      "Epoch 83/100\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.0189 - val_loss: 0.0841\n",
      "Epoch 84/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0182 - val_loss: 0.0924\n",
      "Epoch 85/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0191 - val_loss: 0.0837\n",
      "Epoch 86/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0180 - val_loss: 0.0818\n",
      "Epoch 87/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0204 - val_loss: 0.0812\n",
      "Epoch 88/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0187 - val_loss: 0.0859\n",
      "Epoch 89/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0195 - val_loss: 0.0824\n",
      "Epoch 90/100\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.0192 - val_loss: 0.0831\n",
      "Epoch 91/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0188 - val_loss: 0.0851\n",
      "Epoch 92/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0188 - val_loss: 0.0849\n",
      "Epoch 93/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0195 - val_loss: 0.0855\n",
      "Epoch 94/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0192 - val_loss: 0.0832\n",
      "Epoch 95/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0187 - val_loss: 0.0839\n",
      "Epoch 96/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0191 - val_loss: 0.0863\n",
      "Epoch 97/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0189 - val_loss: 0.0902\n",
      "Epoch 98/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0182 - val_loss: 0.0892\n",
      "Epoch 99/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0168 - val_loss: 0.0828\n",
      "Epoch 100/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0183 - val_loss: 0.0806\n",
      "INFO:tensorflow:Assets written to: a_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: a_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/learn\\NVDA.csv\n",
      "trainx [[[-4.88316170e-01 -4.88226357e-01 -4.89073173e-01 ... -4.10052347e-01\n",
      "   -2.71183127e-02 -1.00350392e+00]\n",
      "  [-4.88857664e-01 -4.88740021e-01 -4.89294148e-01 ... -4.16991532e-01\n",
      "   -9.25995080e-03 -1.00350392e+00]\n",
      "  [-4.88893761e-01 -4.88881728e-01 -4.89054759e-01 ... -4.25563705e-01\n",
      "   -8.64417784e-03 -1.00350392e+00]\n",
      "  ...\n",
      "  [-4.89399171e-01 -4.88775458e-01 -4.89515123e-01 ... -4.12909843e-01\n",
      "    6.75109218e-03  1.00480442e+00]\n",
      "  [-4.88893761e-01 -4.88633751e-01 -4.88999505e-01 ... -4.21073848e-01\n",
      "    5.92889586e-04  1.00480442e+00]\n",
      "  [-4.88532770e-01 -4.88314915e-01 -4.89330975e-01 ... -4.06378514e-01\n",
      "   -1.04914967e-02 -1.00350392e+00]]\n",
      "\n",
      " [[-4.88857664e-01 -4.88740021e-01 -4.89294148e-01 ... -4.16991532e-01\n",
      "   -9.25995080e-03 -1.00350392e+00]\n",
      "  [-4.88893761e-01 -4.88881728e-01 -4.89054759e-01 ... -4.25563705e-01\n",
      "   -8.64417784e-03 -1.00350392e+00]\n",
      "  [-4.88911810e-01 -4.88917151e-01 -4.89294148e-01 ... -4.21073534e-01\n",
      "   -1.72659452e-02 -1.00350392e+00]\n",
      "  ...\n",
      "  [-4.88893761e-01 -4.88633751e-01 -4.88999505e-01 ... -4.21073848e-01\n",
      "    5.92889586e-04  1.00480442e+00]\n",
      "  [-4.88532770e-01 -4.88314915e-01 -4.89330975e-01 ... -4.06378514e-01\n",
      "   -1.04914967e-02 -1.00350392e+00]\n",
      "  [-4.88749371e-01 -4.88704598e-01 -4.89146826e-01 ... -4.19440859e-01\n",
      "   -1.41861345e-02 -1.00350392e+00]]\n",
      "\n",
      " [[-4.88893761e-01 -4.88881728e-01 -4.89054759e-01 ... -4.25563705e-01\n",
      "   -8.64417784e-03 -1.00350392e+00]\n",
      "  [-4.88911810e-01 -4.88917151e-01 -4.89294148e-01 ... -4.21073534e-01\n",
      "   -1.72659452e-02 -1.00350392e+00]\n",
      "  [-4.89182571e-01 -4.89058857e-01 -4.89294148e-01 ... -4.24339199e-01\n",
      "   -4.33329414e-03  1.00480442e+00]\n",
      "  ...\n",
      "  [-4.88532770e-01 -4.88314915e-01 -4.89330975e-01 ... -4.06378514e-01\n",
      "   -1.04914967e-02 -1.00350392e+00]\n",
      "  [-4.88749371e-01 -4.88704598e-01 -4.89146826e-01 ... -4.19440859e-01\n",
      "   -1.41861345e-02 -1.00350392e+00]\n",
      "  [-4.88749371e-01 -4.88704598e-01 -4.89110000e-01 ... -4.20257196e-01\n",
      "   -1.11072697e-02 -1.00350392e+00]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 5.16105272e+00  5.21067874e+00  5.22542939e+00 ...  4.24971671e+00\n",
      "    5.08558692e+00  1.00480442e+00]\n",
      "  [ 5.14178420e+00  5.19775576e+00  5.23532883e+00 ...  3.73246329e+00\n",
      "    2.15332856e+00  1.00480442e+00]\n",
      "  [ 5.26626833e+00  5.16442728e+00  5.24692570e+00 ...  2.70733274e+00\n",
      "   -3.48888893e+00 -1.00350392e+00]\n",
      "  ...\n",
      "  [ 5.96285418e+00  6.04701565e+00  5.87767721e+00 ...  9.06498587e+00\n",
      "   -5.27661642e+00 -1.00350392e+00]\n",
      "  [ 5.92209910e+00  5.83044940e+00  5.90624472e+00 ...  3.44090688e+00\n",
      "    8.05420925e-01  1.00480442e+00]\n",
      "  [ 5.97921214e+00  6.02089694e+00  5.97299690e+00 ...  6.35012866e+00\n",
      "    3.74241298e+00  1.00480442e+00]]\n",
      "\n",
      " [[ 5.14178420e+00  5.19775576e+00  5.23532883e+00 ...  3.73246329e+00\n",
      "    2.15332856e+00  1.00480442e+00]\n",
      "  [ 5.26626833e+00  5.16442728e+00  5.24692570e+00 ...  2.70733274e+00\n",
      "   -3.48888893e+00 -1.00350392e+00]\n",
      "  [ 5.28318048e+00  5.29365954e+00  5.37434894e+00 ...  2.86094154e+00\n",
      "    2.93368316e+00  1.00480442e+00]\n",
      "  ...\n",
      "  [ 5.92209910e+00  5.83044940e+00  5.90624472e+00 ...  3.44090688e+00\n",
      "    8.05420925e-01  1.00480442e+00]\n",
      "  [ 5.97921214e+00  6.02089694e+00  5.97299690e+00 ...  6.35012866e+00\n",
      "    3.74241298e+00  1.00480442e+00]\n",
      "  [ 6.08498236e+00  6.01028632e+00  6.11555262e+00 ...  2.94558172e+00\n",
      "   -1.83833362e+00 -1.00350392e+00]]\n",
      "\n",
      " [[ 5.26626833e+00  5.16442728e+00  5.24692570e+00 ...  2.70733274e+00\n",
      "   -3.48888893e+00 -1.00350392e+00]\n",
      "  [ 5.28318048e+00  5.29365954e+00  5.37434894e+00 ...  2.86094154e+00\n",
      "    2.93368316e+00  1.00480442e+00]\n",
      "  [ 5.39920916e+00  5.34099950e+00  5.47348693e+00 ...  1.75431860e+00\n",
      "   -4.99893850e-01 -1.00350392e+00]\n",
      "  ...\n",
      "  [ 5.97921214e+00  6.02089694e+00  5.97299690e+00 ...  6.35012866e+00\n",
      "    3.74241298e+00  1.00480442e+00]\n",
      "  [ 6.08498236e+00  6.01028632e+00  6.11555262e+00 ...  2.94558172e+00\n",
      "   -1.83833362e+00 -1.00350392e+00]\n",
      "  [ 5.95231903e+00  5.91084552e+00  5.87795990e+00 ...  5.92064378e+00\n",
      "   -4.67598239e+00 -1.00350392e+00]]]\n",
      "trainY [[[-0.48860145]]\n",
      "\n",
      " [[-0.48887218]]\n",
      "\n",
      " [[-0.48898048]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 5.40365738]]\n",
      "\n",
      " [[ 5.38064763]]\n",
      "\n",
      " [[ 5.16815425]]]\n",
      "Model loaded successfully.\n",
      "Epoch 1/100\n",
      "28/28 [==============================] - 2s 23ms/step - loss: 0.0056 - val_loss: 2.2982\n",
      "Epoch 2/100\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0032 - val_loss: 2.0140\n",
      "Epoch 3/100\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0025 - val_loss: 2.0368\n",
      "Epoch 4/100\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0026 - val_loss: 1.8645\n",
      "Epoch 5/100\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0025 - val_loss: 1.8762\n",
      "Epoch 6/100\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0024 - val_loss: 2.1435\n",
      "Epoch 7/100\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0024 - val_loss: 2.1659\n",
      "Epoch 8/100\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.0025 - val_loss: 2.4865\n",
      "Epoch 9/100\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.0024 - val_loss: 2.1732\n",
      "Epoch 10/100\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.0025 - val_loss: 1.9049\n",
      "Epoch 11/100\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.0021 - val_loss: 1.9302\n",
      "Epoch 12/100\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.0023 - val_loss: 1.9417\n",
      "Epoch 13/100\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.0023 - val_loss: 2.1933\n",
      "Epoch 14/100\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.0022 - val_loss: 2.1047\n",
      "Epoch 15/100\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.0022 - val_loss: 1.7496\n",
      "Epoch 16/100\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.0021 - val_loss: 1.8593\n",
      "Epoch 17/100\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.0021 - val_loss: 1.9604\n",
      "Epoch 18/100\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0023 - val_loss: 2.0656\n",
      "Epoch 19/100\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.0020 - val_loss: 2.2825\n",
      "Epoch 20/100\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.0020 - val_loss: 2.0948\n",
      "Epoch 21/100\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0024 - val_loss: 2.0900\n",
      "Epoch 22/100\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0020 - val_loss: 2.0946\n",
      "Epoch 23/100\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0023 - val_loss: 2.3125\n",
      "Epoch 24/100\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.0024 - val_loss: 1.9630\n",
      "Epoch 25/100\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0023 - val_loss: 2.0766\n",
      "Epoch 26/100\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.0022 - val_loss: 2.0172\n",
      "Epoch 27/100\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.0025 - val_loss: 2.0101\n",
      "Epoch 28/100\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.0023 - val_loss: 2.0033\n",
      "Epoch 29/100\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0021 - val_loss: 2.0728\n",
      "Epoch 30/100\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.0021 - val_loss: 2.1091\n",
      "Epoch 31/100\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0024 - val_loss: 2.1179\n",
      "Epoch 32/100\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0022 - val_loss: 2.2505\n",
      "Epoch 33/100\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0023 - val_loss: 2.3998\n",
      "Epoch 34/100\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0022 - val_loss: 2.0810\n",
      "Epoch 35/100\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.0021 - val_loss: 2.0085\n",
      "Epoch 36/100\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.0022 - val_loss: 2.0008\n",
      "Epoch 37/100\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0021 - val_loss: 2.0932\n",
      "Epoch 38/100\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.0021 - val_loss: 2.2433\n",
      "Epoch 39/100\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.0023 - val_loss: 1.9736\n",
      "Epoch 40/100\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0021 - val_loss: 2.0069\n",
      "Epoch 41/100\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0019 - val_loss: 2.0709\n",
      "Epoch 42/100\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.0019 - val_loss: 2.0908\n",
      "Epoch 43/100\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0022 - val_loss: 2.0674\n",
      "Epoch 44/100\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0019 - val_loss: 1.9626\n",
      "Epoch 45/100\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.0024 - val_loss: 2.1462\n",
      "Epoch 46/100\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0023 - val_loss: 2.1928\n",
      "Epoch 47/100\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0024 - val_loss: 2.1732\n",
      "Epoch 48/100\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0023 - val_loss: 2.1919\n",
      "Epoch 49/100\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0026 - val_loss: 1.9619\n",
      "Epoch 50/100\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.0021 - val_loss: 1.9579\n",
      "Epoch 51/100\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0021 - val_loss: 1.9433\n",
      "Epoch 52/100\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.0021 - val_loss: 1.8808\n",
      "Epoch 53/100\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.0022 - val_loss: 2.1584\n",
      "Epoch 54/100\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0020 - val_loss: 2.0263\n",
      "Epoch 55/100\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.0022 - val_loss: 2.0227\n",
      "Epoch 56/100\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.0022 - val_loss: 1.9510\n",
      "Epoch 57/100\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0023 - val_loss: 1.9387\n",
      "Epoch 58/100\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.0023 - val_loss: 1.7503\n",
      "Epoch 59/100\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.0021 - val_loss: 1.9695\n",
      "Epoch 60/100\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0019 - val_loss: 1.9558\n",
      "Epoch 61/100\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0023 - val_loss: 2.0451\n",
      "Epoch 62/100\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.0020 - val_loss: 2.0111\n",
      "Epoch 63/100\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0022 - val_loss: 1.8433\n",
      "Epoch 64/100\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0023 - val_loss: 1.8550\n",
      "Epoch 65/100\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.0021 - val_loss: 1.8717\n",
      "Epoch 66/100\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 0.0020 - val_loss: 1.8655\n",
      "Epoch 67/100\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.0019 - val_loss: 1.9492\n",
      "Epoch 68/100\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.0020 - val_loss: 1.8913\n",
      "Epoch 69/100\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.0020 - val_loss: 1.8467\n",
      "Epoch 70/100\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.0023 - val_loss: 1.9435\n",
      "Epoch 71/100\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0019 - val_loss: 2.1244\n",
      "Epoch 72/100\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.0022 - val_loss: 1.8453\n",
      "Epoch 73/100\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0022 - val_loss: 1.9776\n",
      "Epoch 74/100\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.0021 - val_loss: 2.0736\n",
      "Epoch 75/100\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0023 - val_loss: 1.7835\n",
      "Epoch 76/100\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0022 - val_loss: 1.9258\n",
      "Epoch 77/100\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0021 - val_loss: 1.7913\n",
      "Epoch 78/100\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.0022 - val_loss: 1.8633\n",
      "Epoch 79/100\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0021 - val_loss: 2.1969\n",
      "Epoch 80/100\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0024 - val_loss: 2.0541\n",
      "Epoch 81/100\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.0022 - val_loss: 1.8517\n",
      "Epoch 82/100\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.0023 - val_loss: 1.9454\n",
      "Epoch 83/100\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0022 - val_loss: 1.7305\n",
      "Epoch 84/100\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.0021 - val_loss: 1.9171\n",
      "Epoch 85/100\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 0.0021 - val_loss: 1.7865\n",
      "Epoch 86/100\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 0.0023 - val_loss: 1.9799\n",
      "Epoch 87/100\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.0025 - val_loss: 1.6085\n",
      "Epoch 88/100\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 0.0020 - val_loss: 1.8188\n",
      "Epoch 89/100\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0021 - val_loss: 1.8428\n",
      "Epoch 90/100\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.0019 - val_loss: 1.9345\n",
      "Epoch 91/100\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0020 - val_loss: 1.7639\n",
      "Epoch 92/100\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0022 - val_loss: 1.9061\n",
      "Epoch 93/100\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.0024 - val_loss: 1.9263\n",
      "Epoch 94/100\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0023 - val_loss: 1.6857\n",
      "Epoch 95/100\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0021 - val_loss: 1.7869\n",
      "Epoch 96/100\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 0.0023 - val_loss: 1.7962\n",
      "Epoch 97/100\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.0019 - val_loss: 2.0525\n",
      "Epoch 98/100\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0023 - val_loss: 1.8442\n",
      "Epoch 99/100\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.0021 - val_loss: 1.8801\n",
      "Epoch 100/100\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.0021 - val_loss: 1.7881\n",
      "INFO:tensorflow:Assets written to: a_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: a_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/learn\\TSLA.csv\n",
      "trainx [[[-6.47412739e-01 -6.46950382e-01 -6.50938585e-01 ... -4.90297463e-01\n",
      "   -4.52823703e-02 -9.97429456e-01]\n",
      "  [-6.48764728e-01 -6.48814404e-01 -6.52020422e-01 ... -5.05704865e-01\n",
      "   -5.81657685e-02 -9.97429456e-01]\n",
      "  [-6.50792702e-01 -6.50863509e-01 -6.54017660e-01 ... -5.08395107e-01\n",
      "   -5.96914541e-02 -9.97429456e-01]\n",
      "  ...\n",
      "  [-6.49542111e-01 -6.49640651e-01 -6.51091145e-01 ... -5.37375697e-01\n",
      "   -2.00238817e-02 -9.97429456e-01]\n",
      "  [-6.50346547e-01 -6.50268609e-01 -6.51472565e-01 ... -5.42266997e-01\n",
      "   -1.20683776e-03 -9.97429456e-01]\n",
      "  [-6.50454699e-01 -6.50037252e-01 -6.50869233e-01 ... -5.48625485e-01\n",
      "    1.47279317e-02  1.00470775e+00]]\n",
      "\n",
      " [[-6.48764728e-01 -6.48814404e-01 -6.52020422e-01 ... -5.05704865e-01\n",
      "   -5.81657685e-02 -9.97429456e-01]\n",
      "  [-6.50792702e-01 -6.50863509e-01 -6.54017660e-01 ... -5.08395107e-01\n",
      "   -5.96914541e-02 -9.97429456e-01]\n",
      "  [-6.53226270e-01 -6.53091075e-01 -6.54607116e-01 ... -5.39209912e-01\n",
      "   -3.91925255e-03 -9.97429456e-01]\n",
      "  ...\n",
      "  [-6.50346547e-01 -6.50268609e-01 -6.51472565e-01 ... -5.42266997e-01\n",
      "   -1.20683776e-03 -9.97429456e-01]\n",
      "  [-6.50454699e-01 -6.50037252e-01 -6.50869233e-01 ... -5.48625485e-01\n",
      "    1.47279317e-02  1.00470775e+00]\n",
      "  [-6.49988265e-01 -6.49832348e-01 -6.50390728e-01 ... -5.53272284e-01\n",
      "    7.94702183e-03  1.00470775e+00]]\n",
      "\n",
      " [[-6.50792702e-01 -6.50863509e-01 -6.54017660e-01 ... -5.08395107e-01\n",
      "   -5.96914541e-02 -9.97429456e-01]\n",
      "  [-6.53226270e-01 -6.53091075e-01 -6.54607116e-01 ... -5.39209912e-01\n",
      "   -3.91925255e-03 -9.97429456e-01]\n",
      "  [-6.53402025e-01 -6.52502788e-01 -6.54197963e-01 ... -5.35541483e-01\n",
      "    2.86287079e-02  1.00470775e+00]\n",
      "  ...\n",
      "  [-6.50454699e-01 -6.50037252e-01 -6.50869233e-01 ... -5.48625485e-01\n",
      "    1.47279317e-02  1.00470775e+00]\n",
      "  [-6.49988265e-01 -6.49832348e-01 -6.50390728e-01 ... -5.53272284e-01\n",
      "    7.94702183e-03  1.00470775e+00]\n",
      "  [-6.49778715e-01 -6.49872008e-01 -6.50917780e-01 ... -5.44712555e-01\n",
      "   -3.07147990e-03 -9.97429456e-01]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 1.80210926e+00  1.81853603e+00  1.84039390e+00 ...  1.19045312e+00\n",
      "    1.77859065e+00  1.00470775e+00]\n",
      "  [ 1.86761274e+00  1.91262955e+00  1.92402817e+00 ...  1.45641662e+00\n",
      "    1.66924756e+00  1.00470775e+00]\n",
      "  [ 1.95207787e+00  1.92115631e+00  1.97312696e+00 ...  7.48406685e-01\n",
      "   -1.28516659e-01 -9.97429456e-01]\n",
      "  ...\n",
      "  [ 2.14453269e+00  2.16466895e+00  2.20925870e+00 ...  1.08957077e+00\n",
      "    1.11745842e+00  1.00470775e+00]\n",
      "  [ 2.24207818e+00  2.23338021e+00  2.28477936e+00 ...  1.02904426e+00\n",
      "    9.59805513e-01  1.00470775e+00]\n",
      "  [ 2.27777041e+00  2.26342268e+00  2.31016095e+00 ...  1.13726219e+00\n",
      "    8.17408695e-01  1.00470775e+00]]\n",
      "\n",
      " [[ 1.86761274e+00  1.91262955e+00  1.92402817e+00 ...  1.45641662e+00\n",
      "    1.66924756e+00  1.00470775e+00]\n",
      "  [ 1.95207787e+00  1.92115631e+00  1.97312696e+00 ...  7.48406685e-01\n",
      "   -1.28516659e-01 -9.97429456e-01]\n",
      "  [ 1.97813740e+00  1.95794122e+00  2.03845343e+00 ...  2.77015013e-01\n",
      "    3.03756363e-01  1.00470775e+00]\n",
      "  ...\n",
      "  [ 2.24207818e+00  2.23338021e+00  2.28477936e+00 ...  1.02904426e+00\n",
      "    9.59805513e-01  1.00470775e+00]\n",
      "  [ 2.27777041e+00  2.26342268e+00  2.31016095e+00 ...  1.13726219e+00\n",
      "    8.17408695e-01  1.00470775e+00]\n",
      "  [ 2.33749439e+00  2.30338016e+00  2.34667274e+00 ...  1.23264501e+00\n",
      "   -1.20921066e+00 -9.97429456e-01]]\n",
      "\n",
      " [[ 1.95207787e+00  1.92115631e+00  1.97312696e+00 ...  7.48406685e-01\n",
      "   -1.28516659e-01 -9.97429456e-01]\n",
      "  [ 1.97813740e+00  1.95794122e+00  2.03845343e+00 ...  2.77015013e-01\n",
      "    3.03756363e-01  1.00470775e+00]\n",
      "  [ 2.13925976e+00  2.15425831e+00  2.19677583e+00 ...  1.11708858e+00\n",
      "    8.53011840e-01  1.00470775e+00]\n",
      "  ...\n",
      "  [ 2.27777041e+00  2.26342268e+00  2.31016095e+00 ...  1.13726219e+00\n",
      "    8.17408695e-01  1.00470775e+00]\n",
      "  [ 2.33749439e+00  2.30338016e+00  2.34667274e+00 ...  1.23264501e+00\n",
      "   -1.20921066e+00 -9.97429456e-01]\n",
      "  [ 2.17038924e+00  2.12134041e+00  2.05208038e+00 ...  3.05951555e+00\n",
      "   -4.23006950e+00 -9.97429456e-01]]]\n",
      "trainY [[[-0.65229752]]\n",
      "\n",
      " [[-0.65198627]]\n",
      "\n",
      " [[-0.65173591]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 1.79341207]]\n",
      "\n",
      " [[ 1.82538291]]\n",
      "\n",
      " [[ 1.79808075]]]\n",
      "Model loaded successfully.\n",
      "Epoch 1/100\n",
      "15/15 [==============================] - 2s 42ms/step - loss: 0.0408 - val_loss: 0.3306\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.0320 - val_loss: 0.2060\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.0259 - val_loss: 0.2394\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.0242 - val_loss: 0.2170\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.0212 - val_loss: 0.2448\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.0218 - val_loss: 0.2296\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.0202 - val_loss: 0.2121\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.0165 - val_loss: 0.2222\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.0152 - val_loss: 0.2286\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.0153 - val_loss: 0.2344\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.0149 - val_loss: 0.2001\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.0162 - val_loss: 0.2105\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.0151 - val_loss: 0.2240\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.0138 - val_loss: 0.2055\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.0144 - val_loss: 0.2171\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.0143 - val_loss: 0.1817\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.0132 - val_loss: 0.2382\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.0130 - val_loss: 0.2116\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.0130 - val_loss: 0.2164\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.0135 - val_loss: 0.2197\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.0136 - val_loss: 0.2302\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.0128 - val_loss: 0.1959\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.0131 - val_loss: 0.2193\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.0135 - val_loss: 0.2466\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.0125 - val_loss: 0.2018\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.0139 - val_loss: 0.2288\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.0121 - val_loss: 0.2081\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.0131 - val_loss: 0.2651\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.0137 - val_loss: 0.2108\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.0143 - val_loss: 0.2011\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.0136 - val_loss: 0.2236\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.0147 - val_loss: 0.2147\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.0139 - val_loss: 0.2394\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.0138 - val_loss: 0.2162\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.0141 - val_loss: 0.1985\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.0135 - val_loss: 0.2422\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.0133 - val_loss: 0.2425\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.0125 - val_loss: 0.1949\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.0121 - val_loss: 0.2066\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.0120 - val_loss: 0.2351\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.0131 - val_loss: 0.2075\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.0124 - val_loss: 0.2252\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.0126 - val_loss: 0.2171\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.0120 - val_loss: 0.2214\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.0123 - val_loss: 0.2325\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.0101 - val_loss: 0.1939\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.0130 - val_loss: 0.1982\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.0128 - val_loss: 0.2084\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.0124 - val_loss: 0.2068\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.0139 - val_loss: 0.2263\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.0131 - val_loss: 0.2144\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.0133 - val_loss: 0.2066\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.0121 - val_loss: 0.2071\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.0115 - val_loss: 0.2161\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.0107 - val_loss: 0.2298\n",
      "Epoch 56/100\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.0129 - val_loss: 0.2403\n",
      "Epoch 57/100\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.0134 - val_loss: 0.2109\n",
      "Epoch 58/100\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.0122 - val_loss: 0.2323\n",
      "Epoch 59/100\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.0130 - val_loss: 0.2412\n",
      "Epoch 60/100\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.0135 - val_loss: 0.1998\n",
      "Epoch 61/100\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.0125 - val_loss: 0.1975\n",
      "Epoch 62/100\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.0103 - val_loss: 0.1950\n",
      "Epoch 63/100\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.0119 - val_loss: 0.2230\n",
      "Epoch 64/100\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.0122 - val_loss: 0.2295\n",
      "Epoch 65/100\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.0121 - val_loss: 0.2357\n",
      "Epoch 66/100\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.0145 - val_loss: 0.2049\n",
      "Epoch 67/100\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.0136 - val_loss: 0.2439\n",
      "Epoch 68/100\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.0110 - val_loss: 0.2216\n",
      "Epoch 69/100\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.0138 - val_loss: 0.1991\n",
      "Epoch 70/100\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.0109 - val_loss: 0.2420\n",
      "Epoch 71/100\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.0120 - val_loss: 0.2279\n",
      "Epoch 72/100\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.0115 - val_loss: 0.2310\n",
      "Epoch 73/100\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.0122 - val_loss: 0.2007\n",
      "Epoch 74/100\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.0128 - val_loss: 0.2274\n",
      "Epoch 75/100\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.0119 - val_loss: 0.2377\n",
      "Epoch 76/100\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.0141 - val_loss: 0.1951\n",
      "Epoch 77/100\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.0107 - val_loss: 0.2247\n",
      "Epoch 78/100\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.0111 - val_loss: 0.2237\n",
      "Epoch 79/100\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.0129 - val_loss: 0.2252\n",
      "Epoch 80/100\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.0118 - val_loss: 0.2264\n",
      "Epoch 81/100\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.0121 - val_loss: 0.2206\n",
      "Epoch 82/100\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.0123 - val_loss: 0.2554\n",
      "Epoch 83/100\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.0140 - val_loss: 0.2137\n",
      "Epoch 84/100\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.0120 - val_loss: 0.2535\n",
      "Epoch 85/100\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.0130 - val_loss: 0.2070\n",
      "Epoch 86/100\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.0118 - val_loss: 0.2214\n",
      "Epoch 87/100\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.0113 - val_loss: 0.2237\n",
      "Epoch 88/100\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.0145 - val_loss: 0.2405\n",
      "Epoch 89/100\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.0119 - val_loss: 0.2141\n",
      "Epoch 90/100\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.0117 - val_loss: 0.2155\n",
      "Epoch 91/100\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.0119 - val_loss: 0.2239\n",
      "Epoch 92/100\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.0148 - val_loss: 0.2101\n",
      "Epoch 93/100\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.0105 - val_loss: 0.2127\n",
      "Epoch 94/100\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.0111 - val_loss: 0.1987\n",
      "Epoch 95/100\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.0118 - val_loss: 0.2154\n",
      "Epoch 96/100\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.0111 - val_loss: 0.2076\n",
      "Epoch 97/100\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.0129 - val_loss: 0.2075\n",
      "Epoch 98/100\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.0113 - val_loss: 0.2116\n",
      "Epoch 99/100\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.0126 - val_loss: 0.2372\n",
      "Epoch 100/100\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.0121 - val_loss: 0.2336\n",
      "INFO:tensorflow:Assets written to: a_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: a_model\\assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from dataProcessor import MarketDataProcessor\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "from utils_plot import print_plot_model_loss\n",
    "\n",
    "# Define the path to the data folder\n",
    "data_folder = 'data/learn'\n",
    "output_folder = 'training_plots'  # Specify the output folder\n",
    "\n",
    "# Clean the output folder before each run\n",
    "if os.path.exists(output_folder):\n",
    "    shutil.rmtree(output_folder)  # Remove the folder and its contents\n",
    "\n",
    "# Create the output folder\n",
    "os.makedirs(output_folder)\n",
    "\n",
    "# Get a list of all files in the data folder\n",
    "file_list = [filename for filename in os.listdir(data_folder) if filename.endswith('.csv')]\n",
    "\n",
    "# Loop through each file\n",
    "for filename in file_list:\n",
    "    file_path = os.path.join(data_folder, filename)\n",
    "    print(file_path)\n",
    "\n",
    "    dataProcessor = MarketDataProcessor(file_path)\n",
    "    \n",
    "    # Load model weights if available\n",
    "    try:\n",
    "        model = load_model('a_model')\n",
    "        print(\"Model loaded successfully.\")\n",
    "    except:\n",
    "        print(\"No model found. Training from scratch.\")\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(64, activation='relu', input_shape=(\n",
    "            dataProcessor.trainX.shape[1], dataProcessor.trainX.shape[2]), return_sequences=True))\n",
    "        model.add(LSTM(32, activation='relu', return_sequences=False))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Dense(1))\n",
    "        model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "    #model.summary()\n",
    "\n",
    "    # fit the model\n",
    "    history = model.fit(dataProcessor.trainX, dataProcessor.trainY, epochs=100, batch_size=200, validation_split=0.1, verbose=1)\n",
    "    model.save('a_model')\n",
    "\n",
    "    # Save the plot as an image file in the output folder\n",
    "    output_filename = os.path.join(output_folder, os.path.splitext(filename)[0] + '_plot.png')\n",
    "    print_plot_model_loss(output_filename, history.history['loss'], history.history['val_loss'])  \n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
