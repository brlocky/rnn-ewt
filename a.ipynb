{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/learn\\NVDA.csv\n",
      "Model loaded successfully.\n",
      "Epoch 1/10\n",
      "23/23 [==============================] - 2s 28ms/step - loss: 0.0688 - val_loss: 5.9208\n",
      "Epoch 2/10\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.0634 - val_loss: 6.1564\n",
      "Epoch 3/10\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.0605 - val_loss: 6.1142\n",
      "Epoch 4/10\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.0583 - val_loss: 6.3156\n",
      "Epoch 5/10\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.0571 - val_loss: 6.6084\n",
      "Epoch 6/10\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.0565 - val_loss: 6.9425\n",
      "Epoch 7/10\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.0544 - val_loss: 7.2610\n",
      "Epoch 8/10\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.0605 - val_loss: 5.9556\n",
      "Epoch 9/10\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.0581 - val_loss: 6.2096\n",
      "Epoch 10/10\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.0550 - val_loss: 7.0482\n",
      "INFO:tensorflow:Assets written to: a_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: a_model\\assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from utils import enrich_data, prepare_training_data\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "import matplotlib.pyplot as plt  # Import the matplotlib.pyplot module\n",
    "import os\n",
    "import pandas as pd\n",
    "import shutil\n",
    "\n",
    "from utils_plot import print_plot_model_loss\n",
    "\n",
    "# Define the path to the data folder\n",
    "data_folder = 'data/learn'\n",
    "output_folder = 'training_plots'  # Specify the output folder\n",
    "\n",
    "# Clean the output folder before each run\n",
    "if os.path.exists(output_folder):\n",
    "    shutil.rmtree(output_folder)  # Remove the folder and its contents\n",
    "\n",
    "# Create the output folder\n",
    "os.makedirs(output_folder)\n",
    "\n",
    "# Get a list of all files in the data folder\n",
    "file_list = [filename for filename in os.listdir(data_folder) if filename.endswith('.csv')]\n",
    "\n",
    "# Loop through each file\n",
    "for filename in file_list:\n",
    "    file_path = os.path.join(data_folder, filename)\n",
    "    print(file_path)\n",
    "\n",
    "    # Prepare Data\n",
    "    df, labeled_data, df_for_training, cols = enrich_data(file_path)\n",
    "    #print(df_for_training)\n",
    "\n",
    "    # LSTM uses sigmoid and tanh that are sensitive to magnitude so values need to be normalized\n",
    "    # normalize the dataset\n",
    "    scaler = StandardScaler()\n",
    "    scaler = scaler.fit(df_for_training)\n",
    "    df_for_training_scaled = scaler.transform(df_for_training)\n",
    "    #print('df_for_training', df_for_training)\n",
    "\n",
    "    ## Prepare training data\n",
    "    trainX, trainY = prepare_training_data(df_for_training_scaled)\n",
    "    #print('trainY', trainY)\n",
    "\n",
    "    # Load model weights if available\n",
    "    try:\n",
    "        model = load_model('a_model')\n",
    "        print(\"Model loaded successfully.\")\n",
    "    except:\n",
    "        print(\"No model found. Training from scratch.\")\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(64, activation='relu', input_shape=(\n",
    "            trainX.shape[1], trainX.shape[2]), return_sequences=True))\n",
    "        model.add(LSTM(32, activation='relu', return_sequences=False))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Dense(trainY.shape[1]))\n",
    "        model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "    #model.summary()\n",
    "\n",
    "    # fit the model\n",
    "    history = model.fit(trainX, trainY, epochs=10, batch_size=250, validation_split=0.1, verbose=1)\n",
    "    model.save('a_model')\n",
    "\n",
    "    # Save the plot as an image file in the output folder\n",
    "    output_filename = os.path.join(output_folder, os.path.splitext(filename)[0] + '_plot.png')\n",
    "    print_plot_model_loss(output_filename, history.history['loss'], history.history['val_loss'])  \n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
