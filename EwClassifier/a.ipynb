{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 5, 64)             17920     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 32)                12416     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 5)                 165       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 30501 (119.14 KB)\n",
      "Trainable params: 30501 (119.14 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "INFO:tensorflow:Assets written to: a_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: a_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 222ms/step\n",
      "transformer_predicted [[   170.         174.91667    178.74416    183.8769  101151.29   ]\n",
      " [   170.         174.91667    178.74416    183.8769  101151.29   ]\n",
      " [   170.         174.91667    178.74416    183.8769  101151.29   ]\n",
      " [   170.         174.91667    178.74416    183.8769  101151.29   ]\n",
      " [   170.         174.91667    178.74416    183.8769  101151.29   ]\n",
      " [   170.         174.91667    178.74416    183.8769  101151.29   ]\n",
      " [   170.         174.91667    178.74416    183.8769  101151.29   ]\n",
      " [   170.         174.91667    178.74416    183.8769  101151.29   ]\n",
      " [   170.         174.91667    178.74416    183.8769  101151.29   ]\n",
      " [   170.         174.91667    178.74416    183.8769  101151.29   ]\n",
      " [   170.         174.91667    178.74416    183.8769  101151.29   ]\n",
      " [   170.         185.73685    178.74416    183.8769  101151.29   ]\n",
      " [   170.         174.91667    178.74416    183.8769  101151.29   ]\n",
      " [   170.         174.91667    178.74416    183.8769  101151.29   ]\n",
      " [   170.         174.91667    178.74416    183.8769  101151.29   ]\n",
      " [   170.         174.91667    178.74416    183.8769  101151.29   ]\n",
      " [   170.         174.91667    178.74416    183.8769  101151.29   ]\n",
      " [   170.         174.91667    178.74416    183.8769  101151.29   ]\n",
      " [   170.         174.91667    178.74416    183.8769  101151.29   ]\n",
      " [   170.         185.73685    178.74416    183.8769  101151.29   ]]\n",
      "30\n",
      "20\n",
      "20\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
    "import os\n",
    "import shutil\n",
    "from utils_plot import print_plot_prediction_waves\n",
    "from dataProcessor import MarketDataProcessor\n",
    "from utils_plot import print_plot_model_loss\n",
    "from pandas.tseries.offsets import CustomBusinessDay\n",
    "from pandas.tseries.holiday import USFederalHolidayCalendar\n",
    "\n",
    "# Libraries that will help us extract only business days in the US.\n",
    "# Otherwise our dates would be wrong when we look back (or forward).\n",
    "us_bd = CustomBusinessDay(calendar=USFederalHolidayCalendar())\n",
    "\n",
    "# Define the path to the data folder\n",
    "data_folder = 'data/learn'\n",
    "output_folder = 'training_plots'  # Specify the output folder\n",
    "\n",
    "# Clean the output folder before each run\n",
    "if os.path.exists(output_folder):\n",
    "    shutil.rmtree(output_folder)  # Remove the folder and its contents\n",
    "\n",
    "# Create the output folder\n",
    "os.makedirs(output_folder)\n",
    "\n",
    "# Get a list of all files in the data folder\n",
    "file_list = [filename for filename in os.listdir(data_folder) if filename.endswith('.csv')]\n",
    "\n",
    "# Loop through each file\n",
    "for filename in file_list:\n",
    "    file_path = os.path.join(data_folder, filename)\n",
    "\n",
    "    data = MarketDataProcessor(file_path)\n",
    "\n",
    "    # Load model weights if available\n",
    "    try:\n",
    "        model = load_model('a_model')\n",
    "        print(\"Model loaded successfully.\")\n",
    "    except:\n",
    "        print(\"No model found. Training from scratch.\")\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(64, activation='relu', input_shape=(\n",
    "                    data.trainX.shape[1], data.trainX.shape[2]), return_sequences=True))\n",
    "        model.add(LSTM(32, activation='relu', return_sequences=False))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Dense(units=5, activation='sigmoid'))  # Output layer with 5 units for Wave1 to Wave5\n",
    "        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "        \"\"\"     model = Sequential()\n",
    "        model.add(LSTM(units=64, activation='relu', input_shape=(data.n_past, 5)))  # Adjust input_shape here\n",
    "        model.add(Dense(units=32, activation='relu'))\n",
    "        model.add(Dense(units=5, activation='sigmoid'))  # Output layer with 5 units for Wave1 to Wave5\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) \"\"\"\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    # Train the model\n",
    "    #history = model.fit(data.trainX, data.trainY, epochs=250, batch_size=5, validation_split=0.1, verbose=1)\n",
    "    # fit the model\n",
    "    model.save('a_model')\n",
    "\n",
    "    # Save the plot as an image file in the output folder\n",
    "    output_filename = os.path.join(output_folder, os.path.splitext(filename)[0] + '_plot.png')\n",
    "    #print_plot_model_loss(output_filename, history.history['loss'], history.history['val_loss'])\n",
    "\n",
    "    # Evaluate the model on the test data\n",
    "    #result = model.evaluate(X_test_sequences, y_test_sequences, verbose=1)\n",
    "    #print(\"Evaluation result:\", result)\n",
    "    #loss, accuracy = model.evaluate(X_test_sequences, y_test_sequences, verbose=1)\n",
    "    #print(f'Test loss: {loss:.4f}, Test accuracy: {accuracy:.4f}')\n",
    "\n",
    "    \n",
    "    n_days_for_prediction = len(data.original_data) - 1\n",
    "\n",
    "    # Make prediction using the model\n",
    "    prediction = model.predict(data.trainX[-n_days_for_prediction:])\n",
    "\n",
    "     # Inverse transform using the original scaler\n",
    "    transformer_predicted = data.scaler.inverse_transform(prediction)\n",
    "    print('transformer_predicted', transformer_predicted)\n",
    "\n",
    "    # Determine the wave with the largest index for each row\n",
    "    max_wave_indices = np.argmax(transformer_predicted, axis=1)\n",
    "\n",
    "    # Generate future prediction dates\n",
    "    train_dates = data.original_data['Date']\n",
    "    predict_period_dates = pd.date_range(\n",
    "        list(train_dates)[-n_days_for_prediction], periods=n_days_for_prediction, freq=us_bd).tolist()\n",
    "\n",
    "    # Convert timestamp to date\n",
    "    forecast_dates = []\n",
    "    for period in predict_period_dates:\n",
    "        forecast_dates.append(period.date())\n",
    "\n",
    "    prediction_columns = ['Wave 1', 'Wave 2', 'Wave 3', 'Wave 4', 'Wave 5']\n",
    "\n",
    "    print(len(forecast_dates))\n",
    "    print(len(transformer_predicted[:, 0]))\n",
    "    print(len(transformer_predicted[:, 1]))\n",
    "\n",
    "        # Create a DataFrame for the forecasted values\n",
    "    df_forecast = pd.DataFrame({\n",
    "        'Date': forecast_dates[:len(transformer_predicted[:, 0])],\n",
    "        'Wave 1': transformer_predicted[:, 0],\n",
    "        'Wave 2': transformer_predicted[:, 1],\n",
    "        'Wave 3': transformer_predicted[:, 2],\n",
    "        'Wave 4': transformer_predicted[:, 3],\n",
    "        'Wave 5': transformer_predicted[:, 4],\n",
    "        'Largest_Wave': np.array(prediction_columns)[max_wave_indices]\n",
    "    })\n",
    "\n",
    "    # Filter original data to keep only dates after '2023-01-01'\n",
    "    df_original = data.original_data[-n_days_for_prediction:].copy()\n",
    "\n",
    "    # Convert the 'Date' column to datetime\n",
    "    df_original['Date'] = pd.to_datetime(df_original['Date'])\n",
    "    df_forecast['Date'] = pd.to_datetime(df_forecast['Date'])\n",
    "    \n",
    "    # Get the first date from df_forecast\n",
    "    first_forecast_date = df_forecast['Date'].iloc[0]\n",
    "\n",
    "    # Save the plot as an image file in the output folder\n",
    "    output_filename_close = os.path.join(output_folder, os.path.splitext(filename)[0] + '_ew_plot.png')\n",
    "    print_plot_prediction_waves(output_filename_close, df_original, df_forecast)\n",
    " \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
